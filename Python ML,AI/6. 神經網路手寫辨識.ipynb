{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 初始準備\n",
    "### Keras 可以用各種不同的深度學習套件當底層，我們可以指定用 Tensorflow 以確保執行的一致性。\n",
    "\n",
    "###  %env KERAS_BACKEND = tensorflow\n",
    "###  \n",
    "### 再來是我們標準數據分析動作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 讀入 MNIST 數據庫\n",
    "### MNIST 是有一堆0-9的手寫數字圖庫。有6萬筆訓練資料，1萬筆測試資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andygyr\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train), (x_test,y_test) = mnist.load_data()  # x 是向量， y是答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 118,\n",
       "        219, 166, 118, 118,   6,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 103, 242, 254,\n",
       "        254, 254, 254, 254,  66,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 232, 254,\n",
       "        254, 254, 254, 254, 238,  70,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 104, 244,\n",
       "        254, 224, 254, 254, 254, 141,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 207,\n",
       "        254, 210, 254, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  84,\n",
       "        206, 254, 254, 254, 254,  41,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         24, 209, 254, 254, 254, 171,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  91,\n",
       "        137, 253, 254, 254, 254, 112,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 214, 250,\n",
       "        254, 254, 254, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81, 247, 254,\n",
       "        254, 254, 254, 254, 254, 146,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 246,\n",
       "        254, 254, 254, 254, 254, 171,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  73,\n",
       "         89,  89,  93, 240, 254, 171,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   1, 128, 254, 219,  31,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   7, 254, 254, 214,  28,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 138, 254, 254, 116,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  19, 177,  90,   0,   0,   0,   0,\n",
       "          0,  25, 240, 254, 254,  34,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 164, 254, 215,  63,  36,   0,  51,\n",
       "         89, 206, 254, 254, 139,   8,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  57, 197, 254, 254, 222, 180, 241,\n",
       "        254, 254, 253, 213,  11,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 140, 105, 254, 254, 254, 254,\n",
       "        254, 254, 236,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   7, 117, 117, 165, 254,\n",
       "        254, 239,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = x_train[10] # 用陣列表示圖片，數字越大越黑\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # 28*28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21a12cf12b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X, cmap = 'Greys') # c = color, cmap = theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 輸入格式整理\n",
    "### 現在將要使用的標準神經網路(NN)不吃矩陣，因此要將數據reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape # 60000筆資料，每筆28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,784)\n",
    "x_test = x_test.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 輸出格式整理\n",
    "### 我們可能會想, 我們想學的函數是這樣的型式:\n",
    "\n",
    "### $$\\hat{f} \\colon \\mathbb{R}^{784} \\to \\mathbb{R}$$\n",
    "### 其實這樣不太好! 為什麼呢? 比如說我們的輸入 x 是一張 0 的圖, 因為我們訓練的神經網路總會有點誤差, 所以可能會得到:\n",
    "\n",
    "### $$\\hat{f}(x) = 0.5$$\n",
    "### 那這意思是有可能是 0, 也有可能是 1 嗎!!?? 可是 0 和 1 根本不像啊。換句話說分類的問題這樣做其實不合理!\n",
    "\n",
    "### 於是我們會做 \"1-hot encoding\", 也就是\n",
    "\n",
    "### 1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "### 5 -> [0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "### 等等。因為分類問題基本上都要做這件事, Keras 其實已幫我們準備好套件!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train,10) #分成10類 (0~9)\n",
    "y_test = np_utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[10] # = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立神經網路\n",
    "## 先開一個函數學習機。標準一層一層傳遞的神經網路叫做 Sequential , 於是打開一個空的神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation #activation 激發方程式\n",
    "from keras.optimizers import SGD # 隨機梯度下降法 Stochastic gradient descent\n",
    "# 因為要反覆訓練，隨機的目的是打亂訓練順序，避免記憶答案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 每次用add去加一層，從第一個隱藏層開始。而第一個隱藏層因為 Keras 不知道輸入有幾個 features，所以要告訴它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() # 打開一個 Sequential 型的函數學習機"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 至此為止，先整理一下數據:\n",
    "### input : 784 維\n",
    "### output: 10 維\n",
    "### 第一層 : 4個神經元\n",
    "### 第二層 : 2個神經元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(500, input_dim = 784))  \n",
    "# 加一層 hidden layer，指定4個神經元，並告訴它輸入資料的維度\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(500)) \n",
    "# 接前面的資料，不用告訴它輸入幾維(前面4的神經元就是4維)\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸出有 10 個數字, 所以輸出層的神經元是 10 個! 而如果我們的網路輸出是\n",
    "\n",
    "$$(y_1, y_2, \\ldots, y_{10})$$\n",
    "### 我們還希望\n",
    "\n",
    "$$\\sum_{i=1}^{10} y_i = 1$$\n",
    "### 這可能嗎, 結果是很容易, 就用 softmax 當激發函數就可以!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10)) # 輸出層 10維\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 至此神經網路建立完成\n",
    "###  \n",
    "# 組裝\n",
    "## 與之前不同的是我們還要做 compile 才正式把神經網路建好\n",
    "## 還需做以下步驟:\n",
    "### 1. 決定 loss function，一般是 mse\n",
    "### 2. 決定 optimizer ， 使用標準的SGD\n",
    "### 3. 設定 learning rate\n",
    "## 為了一邊訓練一邊看到結果，可以加設\n",
    "## metrics = ['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse',optimizer=SGD(lr = 0.05), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 檢視一下神經網路的架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3140"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*4+4  # 784個輸入，4個 weight，4個 bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*10+10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 開始訓練神經網路\n",
    "### 一次要訓練幾筆資料(batch_size)，我們100筆調一次參數好了\n",
    "### 這6萬筆資料一共要訓練幾次(epochs)，訓練20次試試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0095 - acc: 0.9442\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0094 - acc: 0.9453\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0092 - acc: 0.9458\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0091 - acc: 0.9466\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0090 - acc: 0.9472\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0089 - acc: 0.9477\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0088 - acc: 0.9482\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0087 - acc: 0.9489\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0086 - acc: 0.9494\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0085 - acc: 0.9499\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.0084 - acc: 0.9503\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0084 - acc: 0.9509\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0083 - acc: 0.9513\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0082 - acc: 0.9519\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0081 - acc: 0.9525\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0080 - acc: 0.9527\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0080 - acc: 0.9532\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0079 - acc: 0.9536\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0078 - acc: 0.9540\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0078 - acc: 0.9544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a13059e48>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs= 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試用結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict放的是神經網路學習的結果，這裡的predict_class會讓Keras選10個輸出機率最大的那類。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意 x_test 已經變成784維的向量，需要將其還原成28*28的矩陣才能當圖形顯示出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(測試編號):\n",
    "    plt.imshow(x_test[測試編號].reshape(28,28), cmap = 'Greys')\n",
    "    print('神經網路判斷為:', predict[測試編號])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神經網路判斷為: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4dc3ad8bea4f1994c01be081fdfdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4999, description='測試編號', max=9999), Button(description='Run Interact', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.test(測試編號)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(test, 測試編號=(0,9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試資料的總狀況"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 104us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.01035383340048138\n",
      "accuracy 0.932\n"
     ]
    }
   ],
   "source": [
    "print('loss:', score[0]) # loss funtion 的平均誤差\n",
    "print('accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將訓練好的神經網路存起來\n",
    "### 若對訓練結果滿意，可以將該神經網路存起來以便日後使用\n",
    "###  \n",
    "### 之前還沒裝 pyh5 要在終端機 (Anaconda Prompt) 下安裝:\n",
    "###  conda install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存檔\n",
    "\n",
    "model_json = model.to_json() # 存成json格式\n",
    "open('My_first_DL.json','w').write(model_json)\n",
    "model.save_weights('My_first_DL_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取檔案\n",
    "\n",
    "# from keras.models import model_from_json\n",
    "# from keras.optimizers import SGD\n",
    "\n",
    "# model = model_from_json(open('My_first_DL').read())\n",
    "# model.load_weights('My_first_DL_weights.h5')\n",
    "# model.compile(loss = 'mse', optimizer=SGD(lr = 0.087))\n",
    "\n",
    "# from keras.datasets import mnist\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# X = x_test[87]\n",
    "# X.shape  --> 28*28\n",
    "# X.reshape(1, 784)  --> 將 X[87] 這筆資料拉平\n",
    "\n",
    "# model.predict_classes(X.reshape(1,784))\n",
    "# plt.imshow(X, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
